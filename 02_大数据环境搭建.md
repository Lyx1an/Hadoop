# 集群规划

<img src="http://cdn.processon.com/6310a0355653bb0c5d12af2b?e=1662037574&token=trhI0BY8QfVrIGn9nENop6JAc6l5nZuxhjQ62UfM:J3nu7p51F9Pgo-YgdO0BCXZKMcw=" alt="img" style="zoom:150%;" />

# 统一环境配置

## `[所有节点]`IP地址设置

- 修改Ip地址

`vi /etc/sysconfig/network-scripts/ifcfg-ens33`

```shell
TYPE="Ethernet"
PROXY_METHOD="none"
BROWSER_ONLY="no"
BOOTPROTO="static"  # 设置为静态ip static
DEFROUTE="yes"
IPV4_FAILURE_FATAL="no"
NAME="ens33"  # 网卡的名称
DEVICE="ens33" # 设备的名称
ONBOOT="yes"  # 设置为yes, 表示开机启动
IPADDR="192.168.46.150"  # ip地址
PREFIX="24"  # 子网掩码
GATEWAY="192.168.46.2" # 网关
DNS1="114.114.115.115"  # DNS
```

- 重启网络服务

> `systemctl restart network`

- 测试网络

> ping www.baidu.com
>
> 如果可以ping通公网: 说明 ip地址和网关都配置正确
>
> 如果通过 ip addr 不能查看到ip地址, 说明配置有错误
>
> 如果可以ping通内网 192.168.46.1 但是不能ping通外网的话, 则说明网关配置有错误

## `[所有节点]`设置主机名

- 编辑主机名配置文件

> vi /etc/hostname
>
> hadoop01

## `[所有节点]`设置域名映射解析

- 编辑hosts文件

> vi /etc/hosts
>
> 192.168.46.145 hadoop01 hadoop01 
> 192.168.46.146 hadoop02 hadoop02
> 192.168.46.147 hadoop03 hadoop03
> 192.168.46.148 biz01 biz01

## `[所有节点]`关闭防火墙和Selinux

- 关闭防火墙

```shell
systemctl stop firewalld.service
systemctl disable firewalld.service
```

- 关闭Selinux

```shell
vi /etc/selinux/config


# This file controls the state of SELinux on the system.
# SELINUX= can take one of these three values:
#     enforcing - SELinux security policy is enforced.
#     permissive - SELinux prints warnings instead of enforcing.
#     disabled - No SELinux policy is loaded.
SELINUX=disabled
# SELINUXTYPE= can take one of three values:
#     targeted - Targeted processes are protected,
#     minimum - Modification of targeted policy. Only selected processes are protected.
#     mls - Multi Level Security protection.
SELINUXTYPE=targeted
```

## `[所有节点]`配置免密登录

1. 在所有节点生成公钥和私钥

   > `ssh-keygen -t rsa`
   >
   > 后面直接所有的交互都敲回车 即可

2. 拷贝公钥到每台服务器

   > ssh-copy-id hadoop01
   >
   > ssh-copy-id hadoop02
   >
   > ssh-copy-id hadoop03

3. 验证ssh登录

   > ssh hadoop01
   >
   > exit  # 退出ssh登录

## `[所有节点]`配置服务器节点时钟同步

1. 在所有节点安装ntpdate 

   > yum  install -y ntpdate 

2. 增加定时任务

   > crontab -e 
   >
   > */1 * * * *  /usr/sbin/ntpdate -u ntp4.aliyun.com > /dev/null 2>&1


## `[所有节点]`安装常用软件

```shell
yum install -y vim
yum install -y net-tools
yum install -y lrzsz
yum install -y rsync
yum install -y wget
```

## `[所有节点]`创建统一目录

```shell
mkdir -p /bigdata/{soft,server}

/bigdata/soft      安装文件的存放目录
/bigdata/server  软件安装的目录
```

# 定义同步数据脚本

## `[所有节点]`安装软件rsync

```shell
yum install -y rsync
```

## `[hadoop01]` 配置同步脚本

```shell
mkdir /root/bin
cd /root/bin
vim xsync

#!/bin/bash
#1 获取命令输入参数的个数，如果个数为0，直接退出命令 
paramnum=$#
echo "paramnum:$paramnum"
if (( paramnum == 0 )); then
    echo no params;
    exit;
fi
# 2 根据传入参数获取文件名称
p1=$1
file_name=`basename $p1` 
echo fname=$file_name
#3 获取输入参数的绝对路径 
pdir=`cd -P $(dirname $p1); pwd`
echo pdir=$pdir 
#4 获取用户名称 
user=`whoami`
#5 循环执行rsync
current=`hostname` 
nodes=$(cat /root/bin/works)
for host in $nodes; do 
  echo ------------------- $host -------------- 
  if [ "$host" != "$current" ];then
     rsync -rvl $pdir/$file_name $user@$host:$pdir
  fi
done
```

## `[hadoop01]`创建works文件

```shell
cd /root/bin

vi workers

hadoop01
hadoop02
hadoop03
```

## 添加环境变量

```shell
vi /etc/profile.d/custom_env.sh
#! /bin/bash
# root/bin
export PATH=$PATH:/root/bin

source /etc/profile
```

设置文件执行权限

```shell
chmod u+x /root/bin/xsync
```

## 测试同步脚本

# jdk环境安装

1. 把安装的软件上传到/bigdata/soft 目录

   ![image-20220619154309897](../../../../../公司管理/大数据方案/电信用户行为分析/课件v2.0/00_其他文档/image/image-20220619154309897.png)

2. 解压到指定目录

   > -C :指定解压到指定目录
   >
   > tar -zxvf /bigdata/soft/jdk-8u241-linux-x64.tar.gz  -C /bigdata/server/

3. 创建一个软链接

   > cd /bigdata/server
   >
   > ln -s jdk1.8.0_241/ jdk1.8

4. 配置环境变量
   

   > vi  /etc/profile.d/custom_env.sh
   >
   > export JAVA_HOME=/bigdata/server/jdk1.8
   > export PATH=$JAVA_HOME/bin:$PATH
   >
   > 重新加载配置文件
   >
   > source /etc/profile
   
5. 测试验证  <img src="image/image-20220619155330268.png" alt="image-20220619155330268" style="zoom:150%;" />

6. 同步至所有节点

   ```shell
   # 同步到biz01, hadoop01, hadoop02, hadoop03
   xsync /etc/profile/custom_env.sh
   xsync /bigdata/server/jdk1.8.0_241
   xsync  /bigdata/server/jdk1.8
   
   scp -r /etc/profile/custom_env.sh biz01:/etc/profile/custom_env.sh
   scp -r /bigdata/server/jdk1.8.0_241 biz01:/bigdata/server/jdk1.8.0_241
   在biz01 创建软链接
   ln -s jdk1.8.0_241/ jdk1.8
   ```

# MySQL数据库安装

## 卸载已经安装的MySQL数据库

```shell
## 查询MySQL相关的依赖
rpm -qa |grep  mysql
## 如果存在, 则通过rpm -e --nodeps 进行卸载
```

## 获取rpm在线安装仓库文件

```shell
wget  https://dev.mysql.com/get/mysql80-community-release-el7-6.noarch.rpm
```

## 安装mysql的仓库文件

```shell
rpm -ivh mysql80-community-release-el7-6.noarch.rpm
```

## 修改mysql仓库的配置文件

```shell
cd /etc/yum.repos.d/
mysql-community.repo: 用于指定下载哪个版本的安装包
mysql-community-source.repo: 用于指定下载哪个版本的源码

`禁用8.0的版本, 启用5.7的版本`
```

## 安装MySQL5.7

```shell
## 导入签名的信息key
rpm --import https://repo.mysql.com/RPM-GPG-KEY-mysql-2022
## 安装5.7
yum install -y  mysql-community-server
```

## 启动数据库

```shell
systemctl  start mysqld  
systemctl status mysqld
systemctl enable mysqld
```

## 登录数据库

```shell
## 查看初始密码
less /var/log/mysqld.log  |grep pass

## 登录数据库
mysql -uroot -p'XRY046OefV<7'
```

## 修改MySQL数据库密码策略

```shell
set global validate_password_length=4;
set global validate_password_policy=0;
```

## 创建远程登录用户

```shell
ALTER USER 'root'@'localhost' IDENTIFIED BY '123456';
#创建一个远程登录用户
create user 'root'@'%' identified by '123456';
## 设置远程登录权限
grant all privileges on *.* to 'root'@'%';
```

## 设置服务器编码为utf8

```shell
vi /etc/my.cnf
## 在mysqld下面设置
character_set_server=utf8

## 重启服务
systemctl restart mysqld
```

# Hadoop集群安装

## 集群规划

|                   | hadoop01 | hadoop02 | hadoop03 |
| ----------------- | -------- | -------- | -------- |
| 角色              | 主节点   | 从节点   | 从节点   |
| NameNode          | √        |          |          |
| DataNode          | √        | √        | √        |
| ResourceManager   | √        |          |          |
| NodeManager       | √        | √        | √        |
| SecondaryNameNode |          | √        |          |
| Historyserver     | √        |          |          |

## 上传安装包到hadoop01

## 解压到指定目录

> tar -zxvf /bigdata/soft/hadoop-3.3.3.tar.gz  -C /bigdata/server/

## 创建软链接

> cd /bigdata/server
>
> ln -s hadoop-3.3.3/ hadoop

## 常见的Hadoop软件目录说明

| 目录     | 作用                             | 说明                                                         |
| -------- | -------------------------------- | ------------------------------------------------------------ |
| bin/     | Hadoop最基本的管理脚本和使用脚本 | hdfs: 文件上传命令<br/>hadoop文件管理基础命令<br/>yarn: 资源调度相关<br/>mapred: 程序运行, 启动历史服务器 |
| etc/     | Hadoop配置文件的目录             | core-site.xml<br/>hdfs-site.xml<br/>mapred-site.xml<br/>yarn-site.xml |
| include/ | 对外提供的编程库头文件           | 对外提供的编程库头文件（具体动态库和静态库在lib目录中），<br />这些头文件均是用C++定义的，通常用于C++程序访问HDFS或者编写MapReduce程序 |
| lib/     | 动态库和静态库                   | 该目录包含了Hadoop对外提供的编程动态库和静态库，<br />与include目录中的头文件结合使用。 |
| libexec/ | shell配置文件                    | 各个服务对用的shell配置文件所在的目录，<br />可用于配置日志输出、启动参数（比如JVM参数）等基本信息。 |
| sbin/    | Hadoop管理命令                   | 主要包含HDFS和YARN中各类服务的启动/关闭脚本                  |
| share/   | 官方自带示例                     | Hadoop各个模块编译后的jar包所在的目录                        |

## Hadoop配置文件修改

Hadoop安装主要就是配置文件的修改，一般在`主节点进行修改`，完毕后scp分发给其他各个`从节点机器`。

### hadoop-env.sh

文件中设置的是Hadoop运行时需要的环境变量。`JAVA_HOME`是必须设置的，即使我们当前的系统中设置了JAVA_HOME，它也是不认识的，因为Hadoop即使是在本机上执行，它也是把当前的执行环境当成`远程服务器`。

> vim hadoop-env.sh
>
> 54行的JAVA_HOME的设置
>
> export JAVA_HOME=/bigdata/server/jdk1.8
>
> 在文件末尾添加如下内容
>
> export HDFS_NAMENODE_USER=root
> export HDFS_DATANODE_USER=root
> export HDFS_SECONDARYNAMENODE_USER=root
> export YARN_RESOURCEMANAGER_USER=root
> export YARN_NODEMANAGER_USER=root

###  core-site.xml

hadoop的核心配置文件，有默认的配置项`core-default.xml`。
core-default.xml与core-site.xml的功能是一样的，如果在core-site.xml里没有配置的属性，则会自动会获取core-default.xml里的相同属性的值。

> cd /bigdata/server/hadoop/etc/hadoop/
> vim core-site.xml 
>
> 在文件的configuration的标签中添加以下内容:
>
> ```xml
> <property>
>  <name>fs.defaultFS</name>
>  <value>hdfs://hadoop01:8020</value>
> </property>
> 
> <property>
>  <name>hadoop.tmp.dir</name>
>  <value>/bigdata/data/hadoop</value>
> </property>
> 
> <!-- 设置HDFS web UI用户身份 -->
> <property>
>  <name>hadoop.http.staticuser.user</name>
>  <value>root</value>
> </property>
> 
> <!-- 整合hive -->
> <property>
>  <name>hadoop.proxyuser.root.hosts</name>
>  <value>*</value>
> </property>
> 
> <property>
>  <name>hadoop.proxyuser.root.groups</name>
>  <value>*</value>
> </property>
> ```

### hdfs-site.xml

HDFS的核心配置文件，有默认的配置项`hdfs-default.xml`。

hdfs-default.xml与hdfs-site.xml的功能是一样的，如果在hdfs-site.xml里没有配置的属性，则会自动会获取hdfs-default.xml里的相同属性的值。

> cd /bigdata/server/hadoop/etc/hadoop/
>
> vim hdfs-site.xml 
>
> ```xml
>  <!-- 指定secondarynamenode运行位置 -->
>  <property>
>      <name>dfs.namenode.secondary.http-address</name>
>      <value>hadoop02:50090</value>
>  </property>
> ```
>
> 

### mapred-site.xml

MapReduce的核心配置文件，有默认的配置项`mapred-default.xml`。

mapred-default.xml与mapred-site.xml的功能是一样的，如果在mapred-site.xml里没有配置的属性，则会自动会获取mapred-default.xml里的相同属性的值。

> cd /bigdata/server/hadoop/etc/hadoop/
>
> vim mapred-site.xml
>
> ```xml
>  <property>
>      <name>mapreduce.framework.name</name>
>      <value>yarn</value>
>  </property>
>  <property>
>      <name>yarn.app.mapreduce.am.env</name>
>      <value>HADOOP_MAPRED_HOME=${HADOOP_HOME}</value>
>  </property>
>  <property>
>      <name>mapreduce.map.env</name>
>      <value>HADOOP_MAPRED_HOME=${HADOOP_HOME}</value>
>  </property>
>  <property>
>      <name>mapreduce.reduce.env</name>
>      <value>HADOOP_MAPRED_HOME=${HADOOP_HOME}</value>
>  </property>
> ```
>
> 

### yarn-site.xml

YARN的核心配置文件，有默认的配置项`yarn-default.xml`。

yarn-default.xml与yarn-site.xml的功能是一样的，如果在yarn-site.xml里没有配置的属性，则会自动会获取yarn-default.xml里的相同属性的值。

> cd /bigdata/server/hadoop/etc/hadoop/
>
> vim yarn-site.xml
>
> ```xml
> <!-- 指定YARN的主角色（ResourceManager）的地址 -->
>  <property>
>      <name>yarn.resourcemanager.hostname</name>
>      <value>hadoop01</value>
>  </property>
> 
>  <!-- NodeManager上运行的附属服务。需配置成mapreduce_shuffle，才可运行MapReduce程序默认值："" -->
>  <property>
>      <name>yarn.nodemanager.aux-services</name>
>      <value>mapreduce_shuffle</value>
>  </property>
> 
>  <!-- 是否将对容器实施物理内存限制 -->
>  <property>
>      <name>yarn.nodemanager.pmem-check-enabled</name>
>      <value>false</value>
>  </property>
> 
>  <!-- 是否将对容器实施虚拟内存限制。 -->
>  <property>
>      <name>yarn.nodemanager.vmem-check-enabled</name>
>      <value>false</value>
>  </property>
>  <!-- 开启日志聚集 -->
>  <property>
>      <name>yarn.log-aggregation-enable</name>
>      <value>true</value>
>  </property>
> 
>  <!-- 设置yarn历史服务器地址 -->
>  <property>
>      <name>yarn.log.server.url</name>
>      <value>http://hadoop01:19888/jobhistory/logs</value>
>  </property>
> 
>  <!-- 保存的时间7天 -->
>  <property>
>      <name>yarn.log-aggregation.retain-seconds</name>
>      <value>604800</value>
>  </property>
> ```
>
> 

### workers

workers文件里面记录的是集群主机名。主要作用是配合一键启动脚本如start-dfs.sh、stop-yarn.sh用来进行集群启动。这时候workers文件里面的主机标记的就是从节点角色所在的机器。

> cd /bigdata/server/hadoop/etc/hadoop/
>
> vim workers
>
> ```properties
> hadoop01
> hadoop02
> hadoop03
> ```

## 同步hadoop软件包到hadoop02和hadoop03

> scp -r hadoop-3.3.3/ hadoop02:$PWD
>
> scp -r hadoop-3.3.3/ hadoop03:$PWD
>
> 在hadoop02节点配置软链接
>
> ln -s hadoop-3.3.3/ hadoop
>
> 在hadoop03节点配置软链接
>
> ln -s hadoop-3.3.3/ hadoop

## `[所有节点]`配置环境变量

> vim /etc/profile.d/custome_env.sh
>
> export HADOOP_HOME=/bigdata/server/hadoop
>
> export PATH=$PATH:$HADOOP_HOME/bin:$HADOOP_HOME/sbin
>
> source /etc/profile

##  Hadoop集群启动

### 启动方式

要启动Hadoop集群，需要启动`HDFS`和`YARN`两个集群。
注意：首次启动HDFS时，必须在主节点`hadoop01`对其进行格式化操作。本质上是一些清理和准备工作，因为此时的HDFS在物理上还是不存在的。

> hadoop namenode -format 

### 手动单个节点启动

在`主节点hadoop01`启动namenode

> cd  /bigdata/server/hadoop/bin
>
> ./hdfs --daemon start namenode

在`hadoop02`启动secondarynamenode

> cd  /bigdata/server/hadoop/bin
>
> ./hdfs --daemon start secondarynamenode

在`所有节点`启动datanode

> cd  /bigdata/server/hadoop/bin
>
> ./hdfs --daemon start datanode

查看进程情况

> jpg
>
> netstat -ntlp
>
> 其中hdfs的web端口: hadoop01:9870已经可以正常访问

在`主节点hadoop01`启动ResouceManager

> cd  /bigdata/server/hadoop/bin
>
> ./yarn --daemon start resourcemanager

在`所有节点`启动Nodemanager

> cd  /bigdata/server/hadoop/bin
>
> ./yarn --daemon start nodemanager



> 如果想要停止某个节点上某个角色，只需要把命令中的`start`改为`stop`即可。

### 一键脚本启动

如果配置了`etc/hadoop/workers`和`ssh免密登录`，则可以使用程序脚本启动所有Hadoop两个集群的相关进程，在主节点所设定的机器上执行。

<span style="color:red;font-weight:bold;font-size:20px">hdfs：/bigdata/server/hadoop/sbin/start-dfs.sh</span>

<span style="color:red;font-weight:bold;font-size:20px">yarn：/bigdata/server/hadoop/sbin/start-yarn.sh</span>

> 停止脚本
>
> hdfs：/bigdata/server/hadoop/sbin/stop-dfs.sh
>
> yarn：/bigdata/server/hadoop/sbin/stop-yarn.sh



> 完整的一键启动hdfs和yarn脚本
>
> start-all.sh: 启动所有的hdfs和yarn的脚本
>
> stop-all.sh: 停止所有的hdfs和yarn的脚本

## 启动后的效果

![image-20220619181708175](image/image-20220619181708175.png)

![image-20220619181723836](image/image-20220619181723836.png)

![image-20220619181745180](image/image-20220619181745180.png)

## 集群Web访问UI

`hdfs: http://hadoop01:9870`

![image-20220619181920391](image/image-20220619181920391.png)

`yarn:http://hadoop01:8088`

![image-20220619182103968](image/image-20220619182103968.png)

## MapReduce JobHistory

JobHistory用来记录已经finished的mapreduce运行日志，日志信息存放于HDFS目录中，默认情况下没有开启此功能，需要在`mapred-site.xml`中配置并手动启动。



### 修改mapred-site.xml

> cd /bigdata/server/hadoop/etc/hadoop/
>
> vim  mapred-site.xml
>
> ```xml
> 	<property>
>      <name>mapreduce.jobhistory.address</name>
>      <value>hadoop02:10020</value>
>  </property>
> 	<property>
>      <name>mapreduce.jobhistory.webapp.address</name>
>      <value>hadoop02:19888</value>
>  </property>
> ```

>scp mapred-site.xml  hadoop02:$PWD
>scp mapred-site.xml  hadoop03:$PWD

## 在hadoop02节点启动JobHistory

> cd /bigdata/server/hadoop/bin
>
> ./mapred --daemon start historyserver

### 访问web管理界面

`http://hadoop02:19888/jobhistory`

## 运行演示程序

> 在hdfs创建一个目录:
>
> hdfs dfs -mkdir /input
>
> 上传文件到hdfs的/input目录
>
> hdfs dfs -put start-all.sh /input
>
> 运行示例程序
>
> hadoop jar /bigdata/server/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.3.3.jar  wordcount /input /output



![image-20220619185752203](image/image-20220619185752203.png)



![image-20220619185835596](image/image-20220619185835596.png)

![image-20220619185856618](image/image-20220619185856618.png)